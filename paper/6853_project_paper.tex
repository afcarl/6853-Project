\documentclass{article}
\usepackage{amsfonts}
\usepackage{cite}
\usepackage{amsmath,amsthm,amssymb}
\usepackage[noend]{algpseudocode}
\usepackage[margin=1.5in]{geometry}
\usepackage{algorithm}
\bibliographystyle{authordate1}
\usepackage[square, sort]{natbib}
\usepackage[utf8]{inputenc}
\usepackage{multicol}
\newcommand\inner[2]{\langle #1, #2 \rangle}
\newcommand*\Let[2]{\State #1 $\gets$ #2}
\algrenewcommand\algorithmicrequire{\textbf{Precondition:}}
\algrenewcommand\algorithmicensure{\textbf{Postcondition:}}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newcommand*\conj[1]{\overline{#1}}
\newcommand*\bb[1]{\mathbb{#1}}
\newcommand*\cc[1]{\mathcal{#1}}
\newcommand*\wto{\rightharpoonup}
\newcommand*\Id{\text{Id}}
\newcommand*\im{\text{im}}
\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\dimens}{dim}
\newtheorem{innercustomgeneric}{\customgenericname}
\providecommand{\customgenericname}{}
\newcommand{\newcustomtheorem}[2]{%
  \newenvironment{#1}[1]
  {%
   \renewcommand\customgenericname{#2}%
   \renewcommand\theinnercustomgeneric{##1}%
   \innercustomgeneric
  }
  {\endinnercustomgeneric}
}

\newcustomtheorem{customthm}{Theorem}
\newcustomtheorem{customlemma}{Lemma}

\title{6.853 Final Project: Generalization and Equilibrium in Generative Adversarial Nets}
\author{Logan Engstrom and Kenny Gea}
\date{\today}

\begin{document}
\maketitle

\section{Literature Review}
\subsection{Introduction}
Generative Adversarial Networks (GANs) are a neural network framework introduced by \citet{Goodfellow2014} for estimating generative models from data. The framework consists of two models, a generator $G$ that captures the distribution of the data, and a discriminator $D$ that predicts the probability that a given sample is from the true data distribution or from the distribution estimated by $G$. Intuitively, $D$ is trained by minimizing the probability of making a mistake in classifying samples, and $G$ is trained by maximizing the probability that $D$ makes a mistake. The framework corresponds to a two player minimax game, so in the space of functions for $G$, $D$, there must exist a $(G,D)$ solution corresponding to a Nash Equilibrium. Since their inception, GANs have become the dominant method for fitting generative models to complex data \citep{Arora17} and have been applied to a variety of problems successfully, such as creating cryptographic protocols \citep{Abadi16} and aiding reinforcement learning \citep{FinnGL16}.

\subsection{Theoretical and Practical Limitations of GANs}
Despite the promise of GANs, fundamental problems in training and architecting GANs persist. Training GANs requires finding a Nash equilibrium of a non convex game parameterized in a high-dimensional, continuous space, a difficult problem \citep{Goodfellow17} \citep{Salimans2016}. Generally GANs are trained using iterative gradient descent optimization techniques designed to find the minimum of a cost function – in particular, these optimization techniques are not designed to find the Nash equilibrium of a game \citep{Salimans2016}. As a result, sometimes when these algorithms are used for finding Nash equilibria, the do not converge; one common problem is of reaching a stable orbit, in which a modification to the discriminators parameters that reduces the discriminator cost could in turn increase the generator’s cost, but then in the next round a modification to the generator’s parameters that reduces the generator’s cost, but increases the discriminator cost, creating a circular feedback loop in which the algorithm never reaches equilibrium \citep{Salimans2016}. In general, training instability leads to GANs being often very hard to train \citep{DBLP:journals/corr/GulrajaniAADC17}.
\\
GANs have practical issues beyond the lack of theoretical guarantees and general training difficulties. Despite breakthroughs in speed and accuracy of generative models for images, large scale images generated with GANs often lose finer texture details and have recurring artifacts \citep{DBLP:journals/corr/LedigTHCATTWS16} \citep{Salimans2016} \citep{DBLP:journals/corr/ShrivastavaPTSW16}. In addition to problems generating images, the applications of GANs to discrete problems is limited due to the difficulty of backpropagation through discrete random variables, along with the general instability of the GAN training objective \citep{Che+al-2017-augmented}. 

\subsection{Recent GAN Improvements}
Experimentally driven GAN research has recently included applying traditional artificial neural networks architectures to GANs. One particularly successful endeavor in this theme has been applying deep convolutional layers to classical GAN problems such as image generation, such as with the DCGAN architecture. Possibly the most active area research has been improving training for GANs, with much of recent work on GANs focussing on finding ways of stabilizing GAN training \citep{Salimans2016} \citep{DBLP:journals/corr/ArjovskyCB17} \citep{DBLP:conf/nips/NowozinCT16} \citep{DBLP:journals/corr/MetzPPS16}. \citet{DBLP:journals/corr/RadfordMC15} published guidelines on how to architect the generator and discriminator for more stable training. They provide specific recommendations after conducting experimental research, such as advocating the use of batch normalization in both networks and the deployment of LeakyReLU activations in the discriminator only. In addition, \citet{DBLP:journals/corr/HjelmJCCB17} provides a solution for more stable training for discrete generative problems using the GAN architecture. \citet{Salimans2016} provides another set of solutions for more stable GAN training. They introduce historical averaging of parameters in an attempt to solve the stable orbit problem, feature mapping to modify the loss function to fit on intermediate layer activations rather than the final layer activations, and a few other small architectural changes. \citet{Salimans2016} also introduced a now-popular evaluation metric for image based GANs based off of accuracy when classifying generated images with the Inception network. One of the most important works in GAN research was \citet{DBLP:journals/corr/ArjovskyCB17}, which introduced a new training objective and architecture (the Wasserstein GAN) that empirically appears to lead to more stable training. Since the Wasserstein GAN was released, a variety of other papers building on the idea have emerged. Some claim to improve training stability via relatively small tweaking to the Wasserstein objective and general architecture \citep{DBLP:journals/corr/GulrajaniAADC17}. In particular, the paper that we examine in this work builds on several aspects of the Wasserstein GAN paper \citep{Arora17}. 

\subsection{Future GAN Work}
GANs are relatively new and are not fully understood at a theoretical level. Particularly, training GANs requires finding a nash equilibrium for high dimensional, continuous, non-convex games, an area of active research that has applications outside of just GANs. Other theoretically oriented open problems in GANs include guaranteeing convergence for certain objectives and architectures, and proving that solutions exist at all for certain objectives and architectures \citep{Arora17}. In addition, GAN objectives cannot ensure that synthetic distributions resulting from generator functions have high diversity \citep{Arora17}. Other future GAN should focus on discrete problems \citep{Che+al-2017-augmented}. Currently, both the generator and discriminator need to have their values be continuous. However, many interesting problems such as natural language processing have discrete inputs, severely limiting the application of GANs. The state of the art solution to transform the discrete space into a continuous space, which has mostly produced unsatisfactory results \citep{Che+al-2017-augmented}.



\bibliography{references.bib}
\end{document}
